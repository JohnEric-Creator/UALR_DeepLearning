{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mx3RoFv47_AG"
   },
   "source": [
    "**STARTING OVER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\admin\\anaconda3a\\lib\\site-packages (22.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 5.3 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.3.1\n",
      "    Uninstalling pip-22.3.1:\n",
      "      Successfully uninstalled pip-22.3.1\n",
      "Successfully installed pip-23.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4-79Gct8CiN",
    "outputId": "702f74be-980d-42b8-9a48-c78dce552a58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\admin\\anaconda3a\\lib\\site-packages (0.1.98)\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\anaconda3a\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from torch) (4.4.0)\n",
      "Collecting transformers==4.11.3\n",
      "  Using cached transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from transformers==4.11.3) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from transformers==4.11.3) (0.0.19)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from transformers==4.11.3) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from transformers==4.11.3) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from transformers==4.11.3) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from transformers==4.11.3) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from transformers==4.11.3) (2.28.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from transformers==4.11.3) (0.0.53)\n",
      "Collecting tokenizers<0.11,>=0.10.1 (from transformers==4.11.3)\n",
      "  Using cached tokenizers-0.10.3.tar.gz (212 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from transformers==4.11.3) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from huggingface-hub>=0.0.17->transformers==4.11.3) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from tqdm>=4.27->transformers==4.11.3) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from requests->transformers==4.11.3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from requests->transformers==4.11.3) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from requests->transformers==4.11.3) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from requests->transformers==4.11.3) (2022.12.7)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from sacremoses->transformers==4.11.3) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from sacremoses->transformers==4.11.3) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from sacremoses->transformers==4.11.3) (1.1.1)\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (pyproject.toml): started\n",
      "  Building wheel for tokenizers (pyproject.toml): finished with status 'error'\n",
      "Failed to build tokenizers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for tokenizers (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [51 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-310\n",
      "  creating build\\lib.win-amd64-cpython-310\\tokenizers\n",
      "  copying py_src\\tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\n",
      "  creating build\\lib.win-amd64-cpython-310\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\models\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\models\n",
      "  creating build\\lib.win-amd64-cpython-310\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\decoders\n",
      "  creating build\\lib.win-amd64-cpython-310\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\normalizers\n",
      "  creating build\\lib.win-amd64-cpython-310\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\pre_tokenizers\n",
      "  creating build\\lib.win-amd64-cpython-310\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\processors\n",
      "  creating build\\lib.win-amd64-cpython-310\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\trainers\n",
      "  creating build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_unigram.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\implementations\n",
      "  creating build\\lib.win-amd64-cpython-310\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\tools\\visualizer.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\tools\\__init__.py -> build\\lib.win-amd64-cpython-310\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\tokenizers\n",
      "  copying py_src\\tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\tools\\visualizer-styles.css -> build\\lib.win-amd64-cpython-310\\tokenizers\\tools\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tokenizers\n",
      "ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge-score==0.0.4 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: absl-py in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from rouge-score==0.0.4) (1.4.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from rouge-score==0.0.4) (3.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from rouge-score==0.0.4) (1.23.5)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from rouge-score==0.0.4) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from nltk->rouge-score==0.0.4) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from nltk->rouge-score==0.0.4) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from nltk->rouge-score==0.0.4) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from nltk->rouge-score==0.0.4) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from click->nltk->rouge-score==0.0.4) (0.4.6)\n",
      "Requirement already satisfied: datasets==1.14.0 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from datasets==1.14.0) (1.23.5)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from datasets==1.14.0) (11.0.0)\n",
      "Requirement already satisfied: dill in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from datasets==1.14.0) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from datasets==1.14.0) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from datasets==1.14.0) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from datasets==1.14.0) (4.64.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from datasets==1.14.0) (0.0.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from datasets==1.14.0) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from datasets==1.14.0) (2022.11.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from datasets==1.14.0) (3.8.1)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0,>=0.0.19 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from datasets==1.14.0) (0.0.19)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from datasets==1.14.0) (22.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from aiohttp->datasets==1.14.0) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from aiohttp->datasets==1.14.0) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from aiohttp->datasets==1.14.0) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from aiohttp->datasets==1.14.0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from aiohttp->datasets==1.14.0) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from aiohttp->datasets==1.14.0) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from aiohttp->datasets==1.14.0) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets==1.14.0) (3.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets==1.14.0) (6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets==1.14.0) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from requests>=2.19.0->datasets==1.14.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from requests>=2.19.0->datasets==1.14.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from requests>=2.19.0->datasets==1.14.0) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from tqdm>=4.62.1->datasets==1.14.0) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from pandas->datasets==1.14.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from pandas->datasets==1.14.0) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets==1.14.0) (1.16.0)\n",
      "Requirement already satisfied: rouge in c:\\users\\admin\\anaconda3a\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from rouge) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\anaconda3a\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\anaconda3a\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece\n",
    "!pip install torch\n",
    "!pip install transformers==4.11.3\n",
    "!pip install rouge-score==0.0.4\n",
    "!pip install datasets==1.14.0\n",
    "!pip install rouge\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qiGzitm8Y2R"
   },
   "source": [
    "**The code block** contains several pip install commands to install required packages such as sentencepiece, torch, transformers, rouge-score, datasets, rouge, and scikit-learn.\n",
    "\n",
    "The first line installs sentencepiece, a library for subword tokenization. The second line installs version 1.9.0 of the PyTorch deep learning framework, while the third line installs version 4.11.3 of the transformers library, a popular library for natural language processing tasks such as text summarization. The fourth line installs version 0.0.4 of the rouge-score package, which is used for evaluating the quality of text summaries. The fifth line installs version 1.14.0 of the datasets package, which provides access to a large number of datasets for machine learning tasks. The sixth line installs the rouge package, which is an alternative package for evaluating the quality of text summaries. Finally, the last line installs scikit-learn, a popular machine learning library for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NIRClymMV5ba"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CommitOperationAdd' from 'huggingface_hub' (C:\\Users\\Admin\\anaconda3a\\lib\\site-packages\\huggingface_hub\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m T5Tokenizer, T5ForConditionalGeneration\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_20newsgroups\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrouge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Rouge\n",
      "File \u001b[1;32m~\\anaconda3a\\lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     logging,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     46\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3a\\lib\\site-packages\\transformers\\dependency_versions_check.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     26\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython tqdm regex requests packaging filelock numpy tokenizers\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39msplit()\n",
      "File \u001b[1;32m~\\anaconda3a\\lib\\site-packages\\transformers\\utils\\__init__.py:57\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     24\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     31\u001b[0m     ContextManagers,\n\u001b[0;32m     32\u001b[0m     ExplicitEnum,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     working_or_temp_dir,\n\u001b[0;32m     56\u001b[0m )\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     58\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[0;32m     59\u001b[0m     DISABLE_TELEMETRY,\n\u001b[0;32m     60\u001b[0m     HF_MODULES_CACHE,\n\u001b[0;32m     61\u001b[0m     HUGGINGFACE_CO_PREFIX,\n\u001b[0;32m     62\u001b[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001b[0;32m     63\u001b[0m     PYTORCH_PRETRAINED_BERT_CACHE,\n\u001b[0;32m     64\u001b[0m     PYTORCH_TRANSFORMERS_CACHE,\n\u001b[0;32m     65\u001b[0m     S3_BUCKET_PREFIX,\n\u001b[0;32m     66\u001b[0m     TRANSFORMERS_CACHE,\n\u001b[0;32m     67\u001b[0m     TRANSFORMERS_DYNAMIC_MODULE_NAME,\n\u001b[0;32m     68\u001b[0m     EntryNotFoundError,\n\u001b[0;32m     69\u001b[0m     PushToHubMixin,\n\u001b[0;32m     70\u001b[0m     RepositoryNotFoundError,\n\u001b[0;32m     71\u001b[0m     RevisionNotFoundError,\n\u001b[0;32m     72\u001b[0m     cached_file,\n\u001b[0;32m     73\u001b[0m     default_cache_path,\n\u001b[0;32m     74\u001b[0m     define_sagemaker_information,\n\u001b[0;32m     75\u001b[0m     download_url,\n\u001b[0;32m     76\u001b[0m     extract_commit_hash,\n\u001b[0;32m     77\u001b[0m     get_cached_models,\n\u001b[0;32m     78\u001b[0m     get_file_from_repo,\n\u001b[0;32m     79\u001b[0m     get_full_repo_name,\n\u001b[0;32m     80\u001b[0m     has_file,\n\u001b[0;32m     81\u001b[0m     http_user_agent,\n\u001b[0;32m     82\u001b[0m     is_offline_mode,\n\u001b[0;32m     83\u001b[0m     is_remote_url,\n\u001b[0;32m     84\u001b[0m     move_cache,\n\u001b[0;32m     85\u001b[0m     send_example_telemetry,\n\u001b[0;32m     86\u001b[0m )\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     88\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[0;32m     89\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m     torch_version,\n\u001b[0;32m    168\u001b[0m )\n\u001b[0;32m    171\u001b[0m WEIGHTS_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch_model.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3a\\lib\\site-packages\\transformers\\utils\\hub.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     CommitOperationAdd,\n\u001b[0;32m     34\u001b[0m     create_commit,\n\u001b[0;32m     35\u001b[0m     create_repo,\n\u001b[0;32m     36\u001b[0m     get_hf_file_metadata,\n\u001b[0;32m     37\u001b[0m     hf_hub_download,\n\u001b[0;32m     38\u001b[0m     hf_hub_url,\n\u001b[0;32m     39\u001b[0m     whoami,\n\u001b[0;32m     40\u001b[0m )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_download\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m REGEX_COMMIT_HASH, http_get\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     43\u001b[0m     EntryNotFoundError,\n\u001b[0;32m     44\u001b[0m     LocalEntryNotFoundError,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     hf_raise_for_status,\n\u001b[0;32m     49\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'CommitOperationAdd' from 'huggingface_hub' (C:\\Users\\Admin\\anaconda3a\\lib\\site-packages\\huggingface_hub\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from rouge import Rouge\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import DataLoader\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzHq2bg7gGKK"
   },
   "source": [
    "**This code block** imports necessary libraries for the text summarization task. Specifically, the libraries imported are:\n",
    "\n",
    "1. torch: PyTorch, a popular deep learning library\n",
    "2. T5Tokenizer and T5ForConditionalGeneration from the transformers library: these classes are used to tokenize input texts and generate summaries using a pre-trained T5 model.\n",
    "3. fetch_20newsgroups from sklearn.datasets: this is used to load the 20 newsgroups dataset, a collection of newsgroup documents.\n",
    "4. Rouge from the rouge library: this is used to evaluate the quality of the generated summaries.\n",
    "5. plotly.express as px: this is used to visualize the results.\n",
    "6. pandas as pd: this is used to manipulate dataframes to create the visualization.\n",
    "7. numpy as np: this is used for numerical computing.\n",
    "8. CountVectorizer from sklearn.feature_extraction.text: this is used to count the frequency of each word in the corpus.\n",
    "9. DataLoader from torch.utils.data: this is used to create a PyTorch DataLoader object to iterate through the test dataset.\n",
    "10. rouge_scorer from rouge_score: this is used to initialize the ROUGE scorer for evaluation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "o1yFTNjw97fB"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fetch_20newsgroups' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the 20 newsgroups dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m newsgroups_data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_20newsgroups\u001b[49m(subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, remove\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfooters\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquotes\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      3\u001b[0m input_texts \u001b[38;5;241m=\u001b[39m newsgroups_data\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m      4\u001b[0m target_texts \u001b[38;5;241m=\u001b[39m [text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m input_texts]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fetch_20newsgroups' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the 20 newsgroups dataset\n",
    "newsgroups_data = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "input_texts = newsgroups_data.data\n",
    "target_texts = [text.split('\\n\\n')[0] for text in input_texts]\n",
    "\n",
    "# Select only 1% of the data\n",
    "num_samples = int(0.01 * len(input_texts))\n",
    "input_texts = input_texts[:num_samples]\n",
    "target_texts = target_texts[:num_samples]\n",
    "\n",
    "# Tokenize inputs and targets\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "input_encodings = tokenizer(input_texts, truncation=True, padding=True)\n",
    "target_encodings = tokenizer(target_texts, truncation=True, padding=True)\n",
    "\n",
    "# Convert the dataset to a DataLoader\n",
    "class NewsGroupsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "test_dataset = NewsGroupsDataset(input_encodings)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Instantiate the model and load pre-trained weights\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "model.eval()\n",
    "\n",
    "# Initialize the ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6Tle2Ae-BJa"
   },
   "source": [
    "**This code block** loads the 20 newsgroups dataset and prepares it for use with a T5 model. The fetch_20newsgroups function from sklearn.datasets is used to retrieve the test subset of the newsgroups dataset, and the headers, footers, and quotes are removed from the data. The input_texts and target_texts are created by splitting the data at the first double newline character, which separates the title of the newsgroup article from the body.\n",
    "\n",
    "Next, only 1% of the dataset is selected by setting num_samples to 1% of the length of input_texts, and then input_texts and target_texts are sliced accordingly. The T5Tokenizer is used to tokenize both the inputs and targets, with padding and truncation enabled, creating input_encodings and target_encodings.\n",
    "\n",
    "The NewsGroupsDataset class is defined to convert the encodings to a PyTorch DataLoader using torch.utils.data.Dataset. This class takes in encodings as a parameter, initializes it as an attribute, and has three methods: __getitem__, which returns a dictionary of input_ids and attention_mask tensors, __len__, which returns the length of input_ids, and __init__, which initializes encodings as an attribute.\n",
    "\n",
    "A test_dataset object is created by instantiating NewsGroupsDataset with input_encodings, and a test_loader object is created by instantiating DataLoader with test_dataset, with batch_size set to 2 and shuffle set to True.\n",
    "\n",
    "A T5ForConditionalGeneration model is created from the t5-small pretrained model using from_pretrained, and the model.eval() method is called to put the model in evaluation mode.\n",
    "\n",
    "Finally, a RougeScorer object is instantiated with rouge1 and stemmer enabled as the parameters. This is used to evaluate the generated summaries against the target summaries later in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "txKs_PtcACU0",
    "outputId": "922ccc39-f304-4cb9-a543-3fdef8408d61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: {'r': 0.6050164339617042, 'p': 0.7729578400679762, 'f': 0.6663070449450748}\n",
      "ROUGE-2: {'r': 0.5674891937355944, 'p': 0.7377997800442674, 'f': 0.6283404349271963}\n",
      "ROUGE-L: {'r': 0.6050164339617042, 'p': 0.7729578400679762, 'f': 0.6663070449450748}\n"
     ]
    }
   ],
   "source": [
    "# Load the 20 newsgroups dataset\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "test_texts = newsgroups_test.data[:int(len(newsgroups_test.data)*0.01)]\n",
    "target_summaries = []\n",
    "generated_summaries = []\n",
    "\n",
    "# Tokenize inputs and targets\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "test_inputs = tokenizer.batch_encode_plus(test_texts, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "for i, input_ids in enumerate(test_inputs['input_ids']):\n",
    "    # Decode the input_ids to string\n",
    "    input_str = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "    input_str = input_str.replace('\\n','')\n",
    "    # Generate a summary\n",
    "    summary_ids = model.generate(input_ids.unsqueeze(0), num_beams=4, max_length=50, early_stopping=True)\n",
    "    generated_summary = tokenizer.decode(summary_ids.squeeze(), skip_special_tokens=True)\n",
    "    # Remove any extra whitespace and add to the list\n",
    "    generated_summary = generated_summary.strip()\n",
    "    generated_summaries.append(generated_summary)\n",
    "    \n",
    "    # Add target summary for scoring\n",
    "    target_summary = newsgroups_test.data[i].split('\\n\\n')[0].strip()\n",
    "    target_summaries.append(target_summary)\n",
    "\n",
    "# Score the summaries using ROUGE\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(generated_summaries, target_summaries, avg=True)\n",
    "\n",
    "# Print the ROUGE scores\n",
    "print(f\"ROUGE-1: {scores['rouge-1']}\")\n",
    "print(f\"ROUGE-2: {scores['rouge-2']}\")\n",
    "print(f\"ROUGE-L: {scores['rouge-l']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNqfRwUg_YNm"
   },
   "source": [
    "**This code block** performs text summarization on a subset of the 20 newsgroups dataset using the T5 model. The dataset is loaded using the fetch_20newsgroups function from the sklearn.datasets module. The subset parameter is set to test, and the remove parameter is set to remove headers, footers, and quotes.\n",
    "\n",
    "The input texts are extracted from the loaded dataset, and a summary target text is created for each input text by splitting the text at the first occurrence of two consecutive newline characters. Only 1% of the data is selected for processing.\n",
    "\n",
    "A T5 tokenizer is instantiated with the from_pretrained method using the t5-small model. The batch_encode_plus method is used to tokenize the input texts, and the resulting encodings are assigned to a variable.\n",
    "\n",
    "A for loop is used to iterate through each encoded input. The encoded input is decoded to a string and passed to the generate method of the T5 model with the num_beams, max_length, and early_stopping parameters set to 4, 50, and True, respectively. The resulting summary is decoded to a string and appended to a list of generated summaries. The target summary for the input is also extracted and appended to a list of target summaries.\n",
    "\n",
    "The Rouge module is imported from the rouge package. The get_scores method of the Rouge class is used to compute the ROUGE-1, ROUGE-2, and ROUGE-L scores for the generated summaries and target summaries. The resulting scores are printed to the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7svdVg2CiJQ"
   },
   "source": [
    "**The below code block** is designed to evaluate the performance of a pre-trained T5 model on the task of summarizing news articles. The first step is to load the 20 newsgroups dataset, which contains a collection of news articles. The subset used here is the test set, and the headers, footers, and quotes are removed. A small percentage (1%) of the data is selected to make the code run efficiently in a standard Google Collaboratory notebook.\n",
    "\n",
    "The inputs and target texts are then tokenized using the T5Tokenizer from the transformers library, with truncation and padding enabled. The data is then converted into a DataLoader object to facilitate batch processing.\n",
    "\n",
    "Next, the model is instantiated and its pre-trained weights are loaded. ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is used as the evaluation metric for the generated summaries.\n",
    "\n",
    "**In the second code block**, the test DataLoader is converted to a list of inputs to make it easier to loop over. For each input, the input text is decoded to a string, a summary is generated using the model, and the target summary is extracted from the original data. ROUGE scores are then calculated for the generated summary using the scorer object initialized in the previous code block. The results are printed for each input along with the input text, target summary, and generated summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sp6a4yJ9B078",
    "outputId": "7ad6833d-3e83-44d1-807d-ae33630597f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 1:\n",
      "I said what a SILLY boy i was, now i have zillions of messages like \"does that include shipping\" \"is it scsi\" \"what rom version is it\" \"will it work on a maximegalon gargantuabrain 9000\" ok, the deal is this - if you live in the twin cities, email me, and set up a time, sure, you can drop round and grab one for a tenner. Else Min order $20 (2 drives) + shipping. No guarantees they are good for any purpose at all (they look newish & clean), no technical negotiations. They are model 525 floppytape, part # 960273-639 revision D. 17 pin floppy style connector on the back Else They go in the bin - life is too short for extended negotiations over $10 items :-) cheers Mike.\n",
      "Target summary: I am a little confused on all of the models of the 88-89 bonnevilles.\n",
      "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
      "differences are far as features or performance. I am also curious to\n",
      "know what the book value is for prefereably the 89 model. And how much\n",
      "less than book value can you usually get them for. In other words how\n",
      "much are they in demand this time of year. I have heard that the mid-spring\n",
      "early summer is the best time to buy.\n",
      "Generated summary: is it scsi\" \"what rom version is it\" \"will it work on a maximegalon gargantuabrain 9000\" ok, the deal is this - if\n",
      "ROUGE scores: {'rouge1': Score(precision=0.3181818181818182, recall=0.07446808510638298, fmeasure=0.12068965517241378), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.18181818181818182, recall=0.0425531914893617, fmeasure=0.06896551724137931)}\n",
      "\n",
      "Input 2:\n",
      "The \"artist renderings\" that I've seen of the HST reboost still have the arrays fully extended, with a cradle holding HST at a 30 degree angle to the Shuttle. I think the rendering was conceived before the array replacemnet was approved, so I'm not sure if the current reboost will occur with the arrays deployed or not. However, it doesn't appear that an array retraction was necessary for reboost. Thanks for the input on GRO's S/A design constraints. That would explain the similar design on UARS. Heck, the MMS project used to design _missions_ with servicing in mind. The XTE spacecraft was originally designed as an on-orbit replacement for the instrument module on EUVE. That way, you get two instruments for the price of one spacecraft bus (the Explorer Platform). A second on-orbit replacement was also considered, with the FUSE telescope.\n",
      "Target summary: I'm not familiar at all with the format of these \"X-Face:\" thingies, but\n",
      "after seeing them in some folks' headers, I've *got* to *see* them (and\n",
      "maybe make one of my own)!\n",
      "Generated summary: reboost. Thanks for the input on the \"artist renderings\" that I've seen of the HST reboost. I think the rendering was conceived before the array replacemnet was\n",
      "ROUGE scores: {'rouge1': Score(precision=0.17857142857142858, recall=0.14285714285714285, fmeasure=0.15873015873015875), 'rouge2': Score(precision=0.037037037037037035, recall=0.029411764705882353, fmeasure=0.032786885245901634), 'rougeL': Score(precision=0.14285714285714285, recall=0.11428571428571428, fmeasure=0.12698412698412698)}\n",
      "\n",
      "Input 3:\n",
      "A friend of mine managed to get a copy of a computerised Greek and Hebrew Lexicon called \"The Word Perfect\" (That is not the word processing package WordPerfect). However, some one wiped out the EXE file, and she has not been able to restore it. There are no distributors of the package in South Africa. I would appreciate it, if some one could email me the file, or at least tell me where I could get it from. My email address is fortmann@superbowl.und.ac.za or fortmann@shrike.und.ac.za Many thanks.\n",
      "Target summary: \n",
      "In a word, yes.\n",
      "\n",
      "Generated summary: managed to get a copy of a computerised Greek and Hebrew Lexicon called \"The Word Perfect\" a friend of mine managed to get a copy of a computerised Greek and Hebrew Lexicon called \"The\n",
      "ROUGE scores: {'rouge1': Score(precision=0.058823529411764705, recall=0.5, fmeasure=0.10526315789473684), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.058823529411764705, recall=0.5, fmeasure=0.10526315789473684)}\n",
      "\n",
      "Input 4:\n",
      "Hello, i'm interested in those devices too. Could also send me your suggestions. Thank in advance. Regards. --\n",
      "Target summary: \n",
      "They were attacking the Iraqis to drive them out of Kuwait,\n",
      "a country whose citizens have close blood and business ties\n",
      "to Saudi citizens.  And me thinks if the US had not helped out\n",
      "the Iraqis would have swallowed Saudi Arabia, too (or at \n",
      "least the eastern oilfields).  And no Muslim country was doing\n",
      "much of anything to help liberate Kuwait and protect Saudi\n",
      "Arabia; indeed, in some masses of citizens were demonstrating\n",
      "in favor of that butcher Saddam (who killed lotsa Muslims),\n",
      "just because he was killing, raping, and looting relatively\n",
      "rich Muslims and also thumbing his nose at the West.\n",
      "Generated summary: , Hello, i'm interested in those devices too. Could also send me your suggestions. Thanks in advance.\n",
      "ROUGE scores: {'rouge1': Score(precision=0.29411764705882354, recall=0.049019607843137254, fmeasure=0.08403361344537814), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.11764705882352941, recall=0.0196078431372549, fmeasure=0.03361344537815126)}\n",
      "\n",
      "Input 5:\n",
      "Iv'e got a problem printing with a StyleWriterII. I am printing from a IIvx with 20 megs ram. I am trying to print a Quark file that has 2 fonts a couple of boxes and 3 gradient fills. Two things happen: I get a \" Disk is full\" error, that I can't find documented, I also have parts of letters that are over one of the gradient fills get cut off. This only happens to the text over the fill. Text adjecent in a different box is uneffected. Any ideas?\n",
      "Target summary: \n",
      "I've just spent two solid months arguing that no such thing as an\n",
      "objective moral system exists.\n",
      "Generated summary: 'e got a problem printing with a StyleWriterII. I am printing from a IIvx with 20 megs ram. I am trying to print a Quark file that has 2 fonts\n",
      "ROUGE scores: {'rouge1': Score(precision=0.06666666666666667, recall=0.1111111111111111, fmeasure=0.08333333333333334), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.06666666666666667, recall=0.1111111111111111, fmeasure=0.08333333333333334)}\n",
      "\n",
      "Input 6:\n",
      "Tom Clancy omitted these key steps to try to prevent groups of people from building a nuclear bomb. However, he asserts that you can find these key steps in any university library. The main point of _Five Minutes To Midnight_ is that it is impossible to prevent the proliferation of nuclear weapons, since it has become easy to acquire the knowledge to build one, and fissible materials are nearly impossible to control. Read this article, or better yet, run to your library yourself and dig up some stuff on constructing a nuclear weapon. Doug Holland\n",
      "Target summary: \n",
      "Elisabeth, let's set the record straight for the nth time, I have not read \n",
      "\"The Yeast Connection\".  So anything that I say is not due to brainwashing \n",
      "by this \"hated\" book.  It's okay I guess to hate the book, by why hate me?\n",
      "Elisabeth, I'm going to quote from Zinsser's Microbiology, 20th Edition.\n",
      "A book that you should be familiar with and not \"hate\". \"Candida species \n",
      "colonize the mucosal surfaces of all humans during birth or shortly \n",
      "thereafter.  The risk of endogenous infection is clearly ever present.  \n",
      "Indeed, candidiasis occurs worldwide and is the most common systemic \n",
      "mycosis.\"  Neutrophils play the main role in preventing a systemic \n",
      "infection(candidiasis) so you would have to have a low neutrophil count or \n",
      "\"sick\" neutrophils to see a systemic infection.  Poor diet and persistent \n",
      "parasitic infestation set many third world residents up for candidiasis.\n",
      "Your assessment of candidiasis in the U.S. is correct and I do not dispute \n",
      "it.\n",
      "Generated summary: , or better yet, run to your library yourself and dig up some stuff on constructing a nuclear weapon. Tom Clancy omitted these key steps to try to prevent groups of people from building a nuclear bomb.\n",
      "ROUGE scores: {'rouge1': Score(precision=0.3333333333333333, recall=0.07453416149068323, fmeasure=0.1218274111675127), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.16666666666666666, recall=0.037267080745341616, fmeasure=0.06091370558375635)}\n",
      "\n",
      "Input 7:\n",
      "Do I ever!!!!!! After 2 years of having health problems that had been cleared up w/allery shots, and not knowing why, I went and was re-tested. I actually did better than when I had been tested 2 years ago.... Then putting 2 + 2 together, I realized that it all started back up when the laser printer came into the office. I kept track of the usage, and on hi use days, I was worse. I got better over the weekends.... The laser printer is gone, I'm 100% better!!!..... Whether it is the toner dust or chemicals, I dont know (I am highly allergic to dust...), but it definitely was the laser printer.... brenda peters carderock div, nswc, david taylor model basin bethesda, md 20084 e-mail : cape@dtvms.dt.navy.mil or\n",
      "Target summary: Dishonest money dwindles away, but he who gathers money little by little makes\n",
      "it grow. \n",
      "Proverbs 13:11\n",
      "\n",
      "Generated summary: , nswc, david taylor model basin bethesda, md 20084 e-mail : cape@dtvms.dt.navy.\n",
      "ROUGE scores: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Input 8:\n",
      "I've just spent two solid months arguing that no such thing as an objective moral system exists.\n",
      "Target summary: A friend of mine managed to get a copy of a computerised Greek and Hebrew \n",
      "Lexicon called \"The Word Perfect\" (That is not the word processing \n",
      "package WordPerfect). However, some one wiped out the EXE file, and she \n",
      "has not been able to restore it. There are no distributors of the package in \n",
      "South Africa. I would appreciate it, if some one could email me the file, or \n",
      "at least tell me where I could get it from. \n",
      "Generated summary: I've just spent two solid months arguing that no such thing as a moral system exists.\n",
      "ROUGE scores: {'rouge1': Score(precision=0.23529411764705882, recall=0.05128205128205128, fmeasure=0.08421052631578947), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.11764705882352941, recall=0.02564102564102564, fmeasure=0.042105263157894736)}\n",
      "\n",
      "Input 9:\n",
      "This is the AP story from Fri morning. As the walls came tumbling down and tear gas filled the air, cult leader David Koresh sprang into action. He left his third-floor bedroom and began looking around the house, making sure women and children were secure and checking that everyone had their gas masks on properly. Within hours, the compound became an inferno. Nine Branch Davidians excaped. This is their story, gleaned from lawyers who spoke with six of them who are jailed on charges that include conspiracy and murder. That day the six said a portable radio offered the only contact with the outside world since Koresh's right-hand man, Steve Schneider, ripped out the compounds's phone line after FBI agents called before dawn Monday saying this was the cults last chance: Come out or prepare to get forced out. They kept their word. By dawn, tanks were battering the Mount Carmel compound, punching for hours to creat holes for tear gas to enter. The BD meanwhile proceeded with their daily routines. Strapped into gas masks, the women did laundry. Others read Bibles in their rooms. The 17 children, all under 10, remained by their mothers' sides. Still, it was hard to ignore what was happening around them. Each time a tank rammed the poorly-constructed building it shook violently. Cult members dodges falling gypsum wallboard and doors. Hundreds of gas canisters hurled in from the armored vehicles were filling the air with noxious fumes. The flying canisters were more frightening than the tanks. At least one man was hit in the face. The gas began filling the air, driven by heavy gusts of wind coming through windows and the holes the tanks made. Scattered throughout the house, the cult members made no efforts to gather. Then the FBI sent in its biggest weapon -- a massive armored vehicle headed for a chamber, lined with cinder blocks, where authorities hoped to find Koresh and Schneider and fire tear gas directly at them. Here the cult members' story diverges from the government's version. The FBI says cult members set fires in three places. But each of the six cult members, in separate discussions with\n",
      "Target summary: Hi,\n",
      "Generated summary: the cults' story diverges from the government's version of the story. cult members set fires in three places, but each of the cult members set fires in three places. the\n",
      "ROUGE scores: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Input 10:\n",
      "You *know* that putting something like this out on the newsgroup is *only* going to generate flames, not discussion. Try adding some substance to the issue of \"gestures\" you mentioned. What is it you feel that Israel *has* offered as a \"gesture\"? What would you (*realistically*) expect to see presented by the Arabs/Palestinians in the way of \"gesture\"? What are the \"rules\" that have been bent by Arab actions? It would seem that the Israeli deportations were seen by the other side as an example of \"changing the rules\".\n",
      "Target summary: :  \n",
      ": well, i have lots of experience with scanning in images and altering\n",
      ": them.  as for changing them back into negatives, is that really possible?\n",
      "Generated summary: . Try adding some substance to the issue of \"gestures\" you mentioned. What is it you feel that Israel *has* offered as a \"gesture\"? What are the \"rules\" that have been bent by\n",
      "ROUGE scores: {'rouge1': Score(precision=0.15625, recall=0.20833333333333334, fmeasure=0.17857142857142858), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.09375, recall=0.125, fmeasure=0.10714285714285714)}\n",
      "\n",
      "Input 11:\n",
      "Bosnian Muslims are citizens od Bosnia-Herzegovina who identify themselves with Bosnian Muslim cultural and religious tradition. In Bosnia, \"Muslim\" is not merely a religious category, but an ethnic one as well. Actually, here are the two contradictory arguments made by people on this subject: (1) There is only Serbian and Croatian nationality, and Bosnian Muslims are simply Croats and Serbs of Islamic faith. (2) Bosnian Muslims are a separate nationality since they do not feel themselves to be Croats nor Serbs. In 1968, argument (2) was accepted by former Yugoslavia as valid, and (1) was soundly rejected. The reasons are pragmatic: even if Bosnian Muslims are Croats and Serbs who converted to Islam under Turkish rule centuries ago, none of the present generation has any clue what was their ancestor's actual nationality. In fact, although Bosnian Muslims have felt drawn to Croatian or Serbian national allegiance, most of them feel they have a separate cultural and historic identity. So, arguments like \"yes, but your ancestors were Croats or Serbs\" carry very little weight. Regardless of what their ancestors might have been, as long as Bosnian Muslims feel that they are a separate national group, that ends the debate. What outsiders say is simply not relevant. In the case of former Yugoslavia, the date is 1971, when \"Muslim nationality\" appeared as a census category for the first time. This was the result of a sequence of decisions over the past decade, from recognizing \"Bosniaks\" as an ethnic group (1961) to February 1968 resolution (in B-H) declaring that Muslims are a separate nation, to formal endorsement of this in January 1969, and eventually to the 1971 inclusion of \"Muslim nationality\" choice in census forms. For comparison, in 1948 census there were three national categories available to Muslims in Bosnia-Herzegovina: Serb-Muslims: 71,991 Croat-Muslims: 25,295 Muslims, ethnically undeclared: 788,403 This clearly demonstrates that Muslims feel themselves to be their own nationality. Only a tiny minority felt able to choose Serb or Croat nationality\n",
      "Target summary: I have uploaded the Windows On-Line Review shareware edition to\n",
      "ftp.cica.indiana.edu as /pub/pc/win3/uploads/wolrs7.zip.\n",
      "Generated summary: in 1948 census, there were three national categories available to Muslims in Bosnia-Herzegovina: Serb-Muslims: 71,991 Croat-Muslims: 25,295 Muslims, ethnic\n",
      "ROUGE scores: {'rouge1': Score(precision=0.041666666666666664, recall=0.045454545454545456, fmeasure=0.043478260869565216), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.041666666666666664, recall=0.045454545454545456, fmeasure=0.043478260869565216)}\n",
      "\n",
      "Input 12:\n",
      "A while back (i.e., several months) someone posted a method for allowing a user to choose (via XMenu and something else??) a window manager interactively at X startup time. Could the original poster (or anyone else) please Email a copy of the method to me, as I have lost the original posting? Thanks. ______________________________________________________________________________ Henry Stilmack ) Computing Systems Manager ) Perform random kindnesses UK/Netherlands/Canada Joint Astronomy Centre ) and senseless acts of beauty 660 N. A'ohoku Place, Hilo, HI 96720 ) hps@jach.Hawaii.Edu 808-969-6530 )\n",
      "Target summary: Most graphics systems I have seen have drawing routines that also specify\n",
      "a color for drawing, like\n",
      "Generated summary: a method for allowing a user to choose (via XMenu and something else??) a window manager interactively at X startup time. Could the original poster (or anyone else) please Email a\n",
      "ROUGE scores: {'rouge1': Score(precision=0.06451612903225806, recall=0.11764705882352941, fmeasure=0.08333333333333333), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.06451612903225806, recall=0.11764705882352941, fmeasure=0.08333333333333333)}\n",
      "\n",
      "Input 13:\n",
      "Why not design the solar arrays to be detachable. if the shuttle is going to retunr the HST, what bother are some arrays. just fit them with a quick release. one space walk, or use the second canadarm to remove the arrays.\n",
      "Target summary: \n",
      "You *know* that putting something like this out on the newsgroup is *only*\n",
      "going to generate flames, not discussion. Try adding some substance to\n",
      "the issue of \"gestures\" you mentioned.\n",
      "Generated summary: s, or use the second canadarm to remove the arrays.\n",
      "ROUGE scores: {'rouge1': Score(precision=0.3, recall=0.1, fmeasure=0.15), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.3, recall=0.1, fmeasure=0.15)}\n",
      "\n",
      "Input 14:\n",
      "I have a little question: I need to convert RGB-coded (Red-Green-Blue) colors into HVS-coded (Hue-Value-Saturnation) colors. Does anyone know which formulas to use? Thanks!\n",
      "Target summary: \n",
      "Accusation?  I thought it was a recommendation.  (I mean, I did grow up there,\n",
      "I oughta know).\n",
      "Generated summary: I have a little question: Do you know which formulas to use? Thanks!\n",
      "ROUGE scores: {'rouge1': Score(precision=0.23076923076923078, recall=0.17647058823529413, fmeasure=0.20000000000000004), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.23076923076923078, recall=0.17647058823529413, fmeasure=0.20000000000000004)}\n",
      "\n",
      "Input 15:\n",
      "We were having a problem with instability in the universal gravitational constant that day: the closer I got to those exposed fangs (still dripping, no doubt, with the viscera of the last foolhardy experimenter cum canine psychology) the bigger and heavier the dog appeared to become. Also, recall that the distribution of the 150lb is one five pound jaw+teeth operated by two 70lb muscles driven by a.005 ounce brain possessing an instinctual heuristic composed of equal parts of bloodlust and ravening hunger. The other 5 lb is, of course, dog poop, but that varies all over the place as the dog deposits it regularly on the painstakingly manicured and tended lawns of the dog's owner's neighbors (whilst continuously replenishing its inexhaustible supply, no doubt by consuming the likes of folks like me). My very thought at the time, but as I looked down at these once formidable instruments of mayhem, I realized they had become weak and atrophied by too many sedentary hours tapping away at my ergonomically-correct CRT keyboard. There was only one option left: I reached down to the toolbox near my car and grasped my Craftsman 150 ft-lb torque wrench, surely the bludgeon of dire necessity if ever there was one. To my amazement and confusion, the setter started shaking and rolling on the grass, then leapt to its feet and vanished down the street, still quivering and occasionally looking back at me. \"Seven at One Blow!\" I exclaimed, flexing my new-found biceps and brandishing my Terrible Weapon of Invincibility as I stalked the now-secure environs of my domicile. It was only later that I found out what the dog apparently knew all along: the wrench was defective, would no longer measure torque accurately, and Sears wouldn't fix it or replace it. What I had interpreted as fear and subservience were in fact unmitigated hilarity and contempt. Exactly: nobody can look quite as silly as we can.\n",
      "Target summary: \n",
      "Probably because it IS rape.\n",
      "Generated summary: , a.005 ounce brain possessing an instinctual heuristic composed of equal parts of bloodlust and ravening hunger. 150lb is one five pound jaw+teeth\n",
      "ROUGE scores: {'rouge1': Score(precision=0.041666666666666664, recall=0.2, fmeasure=0.06896551724137931), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.041666666666666664, recall=0.2, fmeasure=0.06896551724137931)}\n",
      "\n",
      "Input 16:\n",
      "Accusation? I thought it was a recommendation. (I mean, I did grow up there, I oughta know). Bring the truck and about 10 pounds of crawfish and we'll talk.\n",
      "Target summary: From article <C68uBG.K2w@world.std.com>, by cfw@world.std.com (Christopher F Wroten):\n",
      "Good question.\n",
      "Answer: The EISA bus does move 32 bits rather than ISA's 8/(16?)\n",
      "        But it still moves it at about the speed as the ISA bus.\n",
      "        I think that's either 8 or 10 mhz.\n",
      "        The local bus designs also move 32 bits like the EISA, but\n",
      "        they move the data at the cpu speed, up to 40 mhz.\n",
      "        So, on a 33mhz cpu, the local bus is moving 32bit data at\n",
      "        33 mhz, and the EISA is moving 32bit data at 8 or 10 mhz.\n",
      "        So the local bus should be 3 to 4 times faster than EISA on\n",
      "        a 33 mhz cpu.  EISA should be about two (maybe 3) times as\n",
      "        fast as ISA.\n",
      "Generated summary: ation? I thought it was a recommendation. (I mean, I did grow up there, I oughta know). Bring the truck and about 10 pounds of crawfish and we'll talk.\n",
      "ROUGE scores: {'rouge1': Score(precision=0.26666666666666666, recall=0.05970149253731343, fmeasure=0.09756097560975609), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.2, recall=0.04477611940298507, fmeasure=0.07317073170731708)}\n",
      "\n",
      "Input 17:\n",
      "Hello, recently I noticed there is a directory named \"DiskImage\" in my disk. I didn't notice it before and I wonder if while installing an application an image of the disk was created, or if Win3.1 automatically created a backup of its files. I couldn't find any documentation on the diskimage utility; having an image of the disk is taking *a lot* of disk space. Does anybody know if this is just something the people who installed Win3.1 did or it is a backup mechanism? Thanks, Anibal -- --------------------------------------------------------------------------- Anibal Mayorga | 21 Wenark Dr #7 | W: (302) 831-8704 mayorga@cis.udel.edu | Newark, DE 19713 | H: (302) 453-0309\n",
      "Target summary: Iv'e got a problem printing with a StyleWriterII. I am printing from a IIvx\n",
      "with 20 megs ram. I am trying to print a Quark file that has 2 fonts a couple\n",
      "of boxes and 3 gradient fills. \n",
      "Generated summary: , Anibal Mayorga | 21 Wenark Dr #7 | W: (302) 831-8704 mayorga@cis.udel.edu | Newark, DE 19713 | H: (302)\n",
      "ROUGE scores: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Input 18:\n",
      "I have a 90 Eagle Talon and I wanted a pair of GTS Headlight covers. Actually, they are turning signal covers since the Talons that year had pop-up lights. I went to a auto shop and bought the tail-light blackouts for $45, but they did not have the turning signal covers in stock. I asked how much it would be and he told me it would cost me another $40. I thought this was a bit high for two small pieces of plastic. Can anyone find me a cheaper pair or even a used one?\n",
      "Target summary: Hello,\n",
      "i'm interested in those devices too.\n",
      "Could also send me your suggestions.\n",
      "Thank in advance.\n",
      "Regards.\n",
      "-- \n",
      "Generated summary: headlight covers. I bought the tail-light blackouts for $45, but they did not have the turning signal covers in stock. I went to a auto shop and bought the tail-light blackouts for $45,\n",
      "ROUGE scores: {'rouge1': Score(precision=0.05714285714285714, recall=0.1111111111111111, fmeasure=0.07547169811320754), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.05714285714285714, recall=0.1111111111111111, fmeasure=0.07547169811320754)}\n",
      "\n",
      "Input 19:\n",
      "-- Douglas C. Meier | You can't play Electro-magnetic Golf Northwestern University, ACNS | according to the rules of Centrifugal This University is too Commie- | Bumblepuppy. -Huxley, Brave New World Lib Pinko to have these views. | dmeier@casbah.acns.nwu.edu\n",
      "Target summary: I said\n",
      "what a SILLY boy i was, now i have zillions of messages like\n",
      "\"does that include shipping\" \t\t\n",
      "\"is it scsi\"\n",
      "\"what rom version is it\"\n",
      "\"will it work on a maximegalon gargantuabrain 9000\"\n",
      "ok, the deal is this - if you live in the twin cities, email me, and set\n",
      "up a time, sure, you can drop round and grab one for a tenner.\n",
      "Else\n",
      "Min order $20 (2 drives) + shipping. No guarantees they are good for\n",
      "any purpose at all (they look newish & clean), no technical\n",
      "negotiations. They are model 525 floppytape, part # 960273-639\n",
      "revision D. 17 pin floppy style connector on the back\n",
      "Else\n",
      "They go in the bin - life is too short for extended negotiations over\n",
      "$10 items :-)\n",
      "cheers\n",
      "Mike.\n",
      "\n",
      "Generated summary: C. Meier | You can't play Electro-magnetic Golf Northwestern University, ACNS | according rules of Centrifugal This University is too Commie- | Bumblepuppy. -Huxley,\n",
      "ROUGE scores: {'rouge1': Score(precision=0.2608695652173913, recall=0.048, fmeasure=0.08108108108108109), 'rouge2': Score(precision=0.09090909090909091, recall=0.016129032258064516, fmeasure=0.0273972602739726), 'rougeL': Score(precision=0.17391304347826086, recall=0.032, fmeasure=0.05405405405405406)}\n",
      "\n",
      "Input 20:\n",
      "Then Einstein should have had lunch with me at the Tien Fu on Castro Street yesterday, when they handed me a fortune cookie that said \"He who has imagination but not knowledge has wings, but no feet\".\n",
      "Target summary: I just called Texas' legislative bill tracking service and found out\n",
      "that HB 1776 (Concealed Carry) is scheduled for a floor vote TODAY!\n",
      "Let those phone calls roll in.\n",
      "Generated summary: Dann htten Einstein es mir erlauben sollen, gestern bei der Tien Fu auf Castro Street zu essen, wenn er mir ein fortune cookie schickte: \"He who has imagination but not knowledge has wings\n",
      "ROUGE scores: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Input 21:\n",
      "Not this again.\n",
      "Target summary: This is an invitation to send articles to the Informatica magazine.\n",
      "The first fully international issue has been published and echoes \n",
      "are quite favourable. For any information, contact (matjaz.gams@ijs.si). \n",
      "Generated summary: Nicht wieder.\n",
      "ROUGE scores: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Input 22:\n",
      "Let's be careful here. If players' performance was completely random in (Clutch-No Clutch), then you would still expect some players to be good in the clutch every year and some to be not-so-good every year. With two years worth of data, you'd have 1/4 of the players good each year, 1/4 bad each year, and 1/2 would have one good and one bad year. We have 96 players for 5 years ('84-'88). Just flipping a coin, you'd expect 3 players to be good all 5 years and 3 to be bad every year. This is what we actually get-- No. of good years 0 1 2 3 4 5 Clutch performers 4 10 37 24 18 3 Coin flip (random) 3 15 30 30 15 3 Essentially the distribution of clutch performers by number of years of good performance is the same as what you would get if the process leading to deviations from non-clutch performance was completely random. If there was anything to clutch hitting (at least in this definition) that had any predictive capability, you expect to see the number of players at the ends to be much larger than that predicted by flipping a coin. Further, if you limit yourself to players who were a lot above or below average in clutch situations (say, 1 standard deviation from the mean) more than one year, the random explanation still looks good. In the four years ('84-'87) that I looked at the data from Elias, there were 79 (29) players with a minimum of 25 (50) at bats in clutch situations that were 1 sigma from the mean two different years. Of those 79 (29) players, 38 (14) of them changed sign between the two years. In other words, they were great clutch hitters one year and really horrible the other year. If it was just a random process, you'd expect those numbers to be 39.5 (14.5). Everything that's been measured about clutch hitting over a period of years that could be used to predict any ability with any proposed definition has looked like a random process (with the caveat that there may be something related to platoon advantage that could be dragged out of the data--e.g., John Lowenstein probably never had a \"clutch\" AB against a left-\n",
      "Target summary: ********************* NEW PRICE ***********\n",
      "Generated summary: 79 (29) players with a minimum of 25 (50) at bats in clutch situations that were 1 sigma from the mean two different years. if it was just a random process, you'd expect\n",
      "ROUGE scores: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Input 23:\n",
      "No, which is why I want an investigation. Who ever said he was? What is obvious is that he was defending himself, and his followers, from the government. Whether you think he was right or wrong in this is another question. If he was right, then he had the moral right to kill those kgBATF agents. --Ray Cote\n",
      "Target summary: \n",
      "Bosnian Muslims are citizens od Bosnia-Herzegovina who identify themselves\n",
      "with Bosnian Muslim cultural and religious tradition.\n",
      "Generated summary: . --Ray Cote. --Ray CoteRay Cote.\n",
      "ROUGE scores: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Input 24:\n",
      "I'm not familiar at all with the format of these \"X-Face:\" thingies, but after seeing them in some folks' headers, I've *got* to *see* them (and maybe make one of my own)! I've got \"dpg-view\" on my Linux box (which displays \"uncompressed X-Faces\") and I've managed to compile [un]compface too... but now that I'm *looking* for them, I can't seem to find any X-Face:'s in anyones news headers! :-( Could you, would you, please send me your \"X-Face:\" header? I *know* I'll probably get a little swamped, but I can handle it....I hope.\n",
      "Target summary: \n",
      "Generated summary: X-Face:'s in anyones news headers! :-( Could you, would you, please send me your \"X-Face:\" header? :-( Could you, would you,\n",
      "ROUGE scores: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0, recall=0, fmeasure=0)}\n",
      "\n",
      "Input 25:\n",
      "I have one of these monitors. It appears to function OK, but is unhookable to anything standard (CGA,EGA,VGA) - it will plug in but gives fuzzy diagonal noise. I also have a graphics board that is apparently a 3270 graphic board (double card with 2 8-bit bus connectors, and a 9-pin female connector with a picture of monitor). I tried plugging these two into a standard AT to no avail. How can one connect these to (the monitor seems to be of relatively high quality, so I'm curious)? Any special drivers and/or setup needed - I can't locate any jumpers on the card.\n",
      "Target summary: A couple of points :-\n",
      "Generated summary: . I have a graphics board that is apparently a 3270 graphic board (double card with 2 8-bit bus connectors, and a 9-pin female connector with picture of monitor). I tried plugging these two into\n",
      "ROUGE scores: {'rouge1': Score(precision=0.05555555555555555, recall=0.5, fmeasure=0.09999999999999999), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.05555555555555555, recall=0.5, fmeasure=0.09999999999999999)}\n",
      "\n",
      "Input 26:\n",
      "The White House Office of the Press Secretary ----------------------------------------------------------------- For Immediate Release April 19, 1993 STATEMENT OF PRESIDENT CLINTON I am deeply saddened by the loss of life in Waco today. My thoughts and prayers are with the families of David Koresh's victims. The law enforcement agencies involved in the Waco siege recommended the course of action pursued today. The Attorney General informed me of their analysis and judgment and recommended that we proceed with today's action given the risks of maintaining the previous policy indefinitely. I told the Attorney General to do what she thought was right, and I stand by that decision.\n",
      "Target summary: Hi sci.med folks...\n",
      "Generated summary: the of the White House Office of the Press Secretary --------------------------------------------------------------------------------------------------------------\n",
      "ROUGE scores: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Input 27:\n",
      "I've done a bit of looking, and havn't been able to come up with a mailing list or newsgroup for users of Adobe Photoshop. Assuming I've just not missed it, I'll go ahead and see if there is enough interest to start a mailing list (and/or alt. newsgroup). Drop me a note if you might be interested in subscribing. THANKS! --Bob Wier (NOT of the Grateful Dead :-)\n",
      "Target summary: \n",
      "It is said that CELP vocoders can run on the highest speed 486s with\n",
      "some room to spare -- they turn 64kbit (8 bit samples, 8k samples/sec)\n",
      "into 4800 baud. However, DSP is hairy, and I have yet to see actual\n",
      "proof of this in the form of an implementation. I have heard fairly\n",
      "reliable rumors to the effect that a famous internetworking guru has a\n",
      "CELP implementation that runs on Sparcstation 1+'s with some room to\n",
      "spare, but I have not succeeded thus far in getting my hands on a copy\n",
      "-- the guru in question has a reputation for not releasing code\n",
      "without having beaten on it for a very very long time first. \n",
      "Generated summary: a bit of looking, and havn't been able to come up with a mailing list or newsgroup for users of Adobe Photoshop. I'll go ahead and see if there is enough interest to start\n",
      "ROUGE scores: {'rouge1': Score(precision=0.3611111111111111, recall=0.11206896551724138, fmeasure=0.17105263157894737), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.16666666666666666, recall=0.05172413793103448, fmeasure=0.07894736842105264)}\n",
      "\n",
      "Input 28:\n",
      "I have a mac LCII 4/80 purchased last august. Just the cpu and mouse... no monitor or keyboard. $800 OBO\n",
      "Target summary: I have a 90 Eagle Talon and I wanted a pair of GTS \n",
      "Headlight covers.  Actually, they are turning signal\n",
      "covers since the Talons that year had pop-up lights.\n",
      "I went to a auto shop and bought the tail-light \n",
      "blackouts for $45, but they did not have the turning\n",
      "signal covers in stock.  I asked how much it would be\n",
      "and he told me it would cost me another $40.  I thought\n",
      "this was a bit high for two small pieces of plastic.\n",
      "Can anyone find me a cheaper pair or even a used one?\n",
      "\n",
      "Generated summary: mac LCII 4/80 purchased last august. Just the cpu and mouse... no monitor or keyboard.\n",
      "ROUGE scores: {'rouge1': Score(precision=0.1875, recall=0.030927835051546393, fmeasure=0.05309734513274336), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.1875, recall=0.030927835051546393, fmeasure=0.05309734513274336)}\n",
      "\n",
      "Input 29:\n",
      "I am a little confused on all of the models of the 88-89 bonnevilles. I have heard of the LE SE LSE SSE SSEI. Could someone tell me the differences are far as features or performance. I am also curious to know what the book value is for prefereably the 89 model. And how much less than book value can you usually get them for. In other words how much are they in demand this time of year. I have heard that the mid-spring early summer is the best time to buy.\n",
      "Target summary: Hi,\n",
      "I need your help with a problem I have with a 1989 Mitsubishi\n",
      "Galant GS transmission.  The car has a 5 speed manual tranmission.\n",
      "Since the car was bought new, while shifting from 2nd to 3rd,  unless \n",
      "I do it SLOWLY and carefully, it makes a \"popping\" or \"hitting\" sound.\n",
      "The dealer and Mitsubishi customer service (reached by an 800 #) say \n",
      "this is NORMAL for the car.  IS IT?\n",
      "And about a year ago, at 35Kmiles, the stick shift handle got STUCK\n",
      "while attempting to put it in reverse:\n",
      "   1- The shifter would not budge.  The clutch had no effect.\n",
      "   2- The front tires would not budge, even when the clutch is\n",
      "      fully depressed.\n",
      "   3- If the clutch is released the engine would die.\n",
      "   4- Assuming that some gear was engaged while the shifter was\n",
      "      stuck, I could not make the car move.  It acted as if\n",
      "      it were in Neutral(except for dying when clutch is released.)\n",
      "   5- I finally was able to release the shifter by having \n",
      "      someone rock the car back and forth (less than an inch),\n",
      "      while I depressed the clutch and jiggled the shifter.\n",
      "   6- The shifter acted normally after that.\n",
      "Generated summary: . I am a little confused on all of the models of the 88-89 bonnevilles. I have heard of the LE SE LSE SSE SSEI. Could someone tell me the differences are far as features or\n",
      "ROUGE scores: {'rouge1': Score(precision=0.3333333333333333, recall=0.06091370558375635, fmeasure=0.10300429184549355), 'rouge2': Score(precision=0.02857142857142857, recall=0.00510204081632653, fmeasure=0.008658008658008656), 'rougeL': Score(precision=0.25, recall=0.04568527918781726, fmeasure=0.07725321888412016)}\n",
      "\n",
      "Input 30:\n",
      "Hi, We have a requirement for dynamically closing and opening different display servers within an X application in a manner such that at any time there is only one display associated with the client. Assumming a proper cleanup is done during the transition should we anticipate any problems.\n",
      "Target summary: \n",
      "Generated summary: a proper cleanup is done during the transition should we anticipate any problems. Hi, We have a requirement for dynamically closing and opening different display servers within an X application in a manner such that at any time there is only\n",
      "ROUGE scores: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0, recall=0, fmeasure=0)}\n",
      "\n",
      "Input 31:\n",
      "Most graphics systems I have seen have drawing routines that also specify a color for drawing, like Drawpoint(x,y,color) or Drawline(x1,y1,x2,y2,color) or Fillrectangle(x1,y1,x2,y2,color) With X, I have to do something like XSetForeground(current_color) XDrawPoint(d,w,x,y) Why split this into two functions? Why did X designers decide to not associate the color with the object being drawn, and instead associate it with the display it is being drawn on?\n",
      "Target summary: I am writing a X-based dosemu which requires XKeyReleasedEvent. \n",
      "I found the keycode of XKeyReleasedEvent is wrong.   If I run the program on\n",
      "a Linux host(XFree1.2) with  DISPLAY set to the local Linux and to\n",
      "the Sun host (X11R5), the two keycodes from the two Xservers are different. \n",
      "Of course, the keycode of XKeyPressedEvent is O.K.\n",
      "Generated summary: graphics systems have drawing routines that specify a color for drawing, like Drawpoint(x,y,color) or Drawline(x1,y1,x2,y2,color) or Fillrectangle(x1,y1,x\n",
      "ROUGE scores: {'rouge1': Score(precision=0.07142857142857142, recall=0.03333333333333333, fmeasure=0.045454545454545456), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.07142857142857142, recall=0.03333333333333333, fmeasure=0.045454545454545456)}\n",
      "\n",
      "Input 32:\n",
      "From article C68uBG.K2w@world.std.com>, by cfw@world.std.com (Christopher F Wroten): Good question. Answer: The EISA bus does move 32 bits rather than ISA's 8/(16?) But it still moves it at about the speed as the ISA bus. I think that's either 8 or 10 mhz. The local bus designs also move 32 bits like the EISA, but they move the data at the cpu speed, up to 40 mhz. So, on a 33mhz cpu, the local bus is moving 32bit data at 33 mhz, and the EISA is moving 32bit data at 8 or 10 mhz. So the local bus should be 3 to 4 times faster than EISA on a 33 mhz cpu. EISA should be about two (maybe 3) times as fast as ISA. That's a very good question. The EISA bus does have more advantages over the ISA bus than just it's width. For example: more/better interrupts and bus mastering. But these other factors do not impact a video card very much. They have more impact on file servers with multiple hard drives, full-throttle network cards, cd-roms, etc.\n",
      "Target summary: A while back (i.e., several months) someone posted a method for allowing \n",
      "a user to choose (via XMenu and something else??) a window manager \n",
      "interactively at X startup time. Could the original poster (or anyone \n",
      "else) please Email a copy of the method to me, as I have lost the \n",
      "original posting? Thanks.\n",
      "Generated summary: cfw@world.std.com (Christopher F Wroten): The EISA bus does move 32 bits rather than ISA's 8/(16?) But it still moves it at about the\n",
      "ROUGE scores: {'rouge1': Score(precision=0.10714285714285714, recall=0.05555555555555555, fmeasure=0.07317073170731708), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.07142857142857142, recall=0.037037037037037035, fmeasure=0.04878048780487805)}\n",
      "\n",
      "Input 33:\n",
      "Hmmm. I gave two examples which matched your objective criteria, and your response was some subjective claptrap about them being 'lame'. You never did counter the fact that those examples fit your objective criteria. One wonders who's playing semantic games, here. -- Rick Schaut UUCP:...uunet | uw-beaver!microsoft!richs\n",
      "Target summary: I'm trying to find a program that will stop the Macs from spitting out\n",
      "their Boot Disk. I was told one exists but I can't find it.\n",
      "Generated summary: that match your objective criteria. I gave two examples which match your objective criteria, and your response was some subjective claptrap about them being 'lame' one wonders who's playing semantic games, here. -- Rick\n",
      "ROUGE scores: {'rouge1': Score(precision=0.11764705882352941, recall=0.13793103448275862, fmeasure=0.126984126984127), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.11764705882352941, recall=0.13793103448275862, fmeasure=0.126984126984127)}\n",
      "\n",
      "Input 34:\n",
      "Hi sci.med folks... I would like to know anything you folks can tell me regarding Lithium. I have a 10 year old son that lives with my ex-wife. She has been having difficulty with his behavior and has had him on Ritalin, Tofranil, and now wants to try Lithuim at the local doctors suggestion. I would like to know whatever is important that I should know. I worry about this sort of thing and would like pros/cons regarding Lithium therapy. I have a booklet from the \"Lithium Information Center\" based at the University of Wisconsin, but feel that it is pro-lithium and would be interested in comments from the \"not necessarily PRO\" side of the fence. I am a concerned father and just wish to be well informed... Thanks for any information you can provide. Please email me directly...\n",
      "Target summary: Recently, I have been getting a CMOS Checksum error when I first turn on my\n",
      "computer.  It doesn't happen everytime I turn it on, nor can I predict when it\n",
      "is going to happen.  I have an AMI BIOS and all of the setting are lost, for\n",
      "example the drive types and the password options.  However, the date and time\n",
      "remain correct.  If anyone knows what can be causing this, please let me know.\n",
      "Generated summary: ...... I am a concerned father and just wish to be well informed... Hi sci.med folks... I would like to know anything you folks can tell me regarding Lithium. I\n",
      "ROUGE scores: {'rouge1': Score(precision=0.3333333333333333, recall=0.13333333333333333, fmeasure=0.19047619047619044), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.23333333333333334, recall=0.09333333333333334, fmeasure=0.13333333333333333)}\n",
      "\n",
      "Input 35:\n",
      ": : well, i have lots of experience with scanning in images and altering : them. as for changing them back into negatives, is that really possible? : (stuff deleted) : jennifer urso: the oh-so bitter woman of utter blahness(but cheerful : undertones) I use Aldus Photostyler on the PC and I can turn a colour or black and white image into a negative or turn a negative into a colour or black and white image. I don't know how it does it but it works well. To test it I scanned a negative and used Aldus to create a positive. It looked better than the print that the film developers gave me. --\n",
      "Target summary: Forwarded from Neal Ausman, Galileo Mission Director\n",
      "Generated summary: : : well, i have lots of experience with scanning in images and altering : them. : : well, i have lots of experience with scanning in images and altering : them. as for\n",
      "ROUGE scores: {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
      "\n",
      "Input 36:\n",
      "[stuff deleted] I have a similiar question relating to anti-alaising that my friend has asked to have posted to the more knowledgable in this group. I'm sorry if this is an FAQ. \"What anti-alaising methods do Persistance Of Vision & Polyray use?\" Thank you in advance. You can either email me or reply (or flame me if it is an FAQ :-) )\n",
      "Target summary: [stuff deleted]\n",
      "I have a similiar question relating to anti-alaising that my friend has asked\n",
      "to have posted to the more knowledgable in this group. I'm sorry if this is\n",
      "an FAQ.\n",
      "Generated summary: . \"What anti-alaising methods do Persistance Of Vision & Polyray use?\" Thank you in advance. You can either email me or reply (or flame me if it is an FAQ :-)\n",
      "ROUGE scores: {'rouge1': Score(precision=0.2413793103448276, recall=0.20588235294117646, fmeasure=0.22222222222222224), 'rouge2': Score(precision=0.10714285714285714, recall=0.09090909090909091, fmeasure=0.09836065573770493), 'rougeL': Score(precision=0.2413793103448276, recall=0.20588235294117646, fmeasure=0.22222222222222224)}\n",
      "\n",
      "Input 37:\n",
      "Does any one know of a decent quality library of routines for performing 3D graphics modelling on the PC? Ideally the routines would be embeded in our application program. Requirements (wish list): - flat surface modelling (simple phong shading optional) - ability to plot hidden-line drawings - Texture mapping -- both procedural and bit map - modeling light sources (local, distant, and spot lights) - Ray-tracing - Radiosity (optional) Any comments would be appreciated. John Chinnick -- jchinnic@mach1.wlu.ca phone : (519) 888-9666\n",
      "Target summary: } Last night, Boston Red Sox win its 11 games of 14 games by beating Seattle\n",
      "} 5-2.  Roger Clemson pitch not so dominate.  He walked at least 6 man in\n",
      "} first 6 inns.  But Valetin and Greenwell hit homeruns and Red Sox prevail.\n",
      "Generated summary: : - flat surface modelling (simple phong shading optional) - ability to plot hidden-line drawings - Texture mapping -- both procedural and bit map - modeling light sources (local, distant, and\n",
      "ROUGE scores: {'rouge1': Score(precision=0.07692307692307693, recall=0.046511627906976744, fmeasure=0.057971014492753624), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.07692307692307693, recall=0.046511627906976744, fmeasure=0.057971014492753624)}\n",
      "\n",
      "Input 38:\n",
      "********************* NEW PRICE *********** I have an extra copy of Lotus 1-2-3 ver 3.4 for DOS. this package was originally $600. I'd like to get $75 for it. please reply by e-mail to jth@bach.udel.edu\n",
      "Target summary: Is there any third party video ram adapter for vewing 24 bit color on LCII?\n",
      "I heard that Apple is selling it aroung 160$.\n",
      "Please e-mail me.\n",
      "Thanks.\n",
      "Young\n",
      "youyj@mace.cc.purdue.edu\n",
      "Generated summary: ********* NEW PRICE *********** I have an extra copy of Lotus 1-2-3 ver 3.4 for DOS. this package was originally $600. I'd like $75 for it. please reply by email to j\n",
      "ROUGE scores: {'rouge1': Score(precision=0.11764705882352941, recall=0.11428571428571428, fmeasure=0.11594202898550723), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.11764705882352941, recall=0.11428571428571428, fmeasure=0.11594202898550723)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the test DataLoader to a list of inputs\n",
    "test_inputs = [inputs for inputs in test_loader]\n",
    "\n",
    "# Loop over the test inputs and generated summaries to calculate ROUGE scores\n",
    "target_summaries = []\n",
    "generated_summaries = []\n",
    "rouge_scores = []\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "for i, input_ids in enumerate(test_inputs):\n",
    "    # Decode the input_ids to string\n",
    "    input_str = tokenizer.decode(input_ids['input_ids'][0], skip_special_tokens=True)\n",
    "\n",
    "    # Generate a summary using the model\n",
    "    summary_ids = model.generate(input_ids=input_ids['input_ids'], num_beams=4, max_length=50, early_stopping=True)\n",
    "    summary_str = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Add the target summary and generated summary to the lists\n",
    "    target_summary = target_texts[i]\n",
    "    generated_summaries.append(summary_str)\n",
    "    target_summaries.append(target_summary)\n",
    "\n",
    "    # Calculate ROUGE scores for the generated summary\n",
    "    rouge = scorer.score(target_summary, summary_str)\n",
    "    rouge_scores.append(rouge)\n",
    "    print(f\"Input {i+1}:\\n{input_str}\\nTarget summary: {target_summary}\\nGenerated summary: {summary_str}\\nROUGE scores: {rouge}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3WFmSmVCoZc"
   },
   "source": [
    "Visualization Code block 1: Bar chart to visualize top N words in the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSB4AvMQmTyA"
   },
   "source": [
    "**The following code block** is aimed at creating a bar chart of the top N words by frequency in a corpus. The first step is to join the input_texts into a single list of strings called corpus. Then, the CountVectorizer object from scikit-learn is created with English stop words to count the frequency of each word in the corpus. The top N words by frequency are then extracted and sorted in descending order using a lambda function. The words and freqs variables contain the top N words and their frequencies, respectively. A DataFrame object is created to store the top N words and their frequencies. Finally, a bar chart is created using Plotly Express library, where the x-axis corresponds to the words and the y-axis corresponds to their respective frequencies, with the chart title indicating the top N words in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "Sc6sqLR-CkOz",
    "outputId": "eb4fe037-b80b-4807-945d-c2058ba96cee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"dbe46988-4512-46fe-a0ff-fb9c914e6485\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dbe46988-4512-46fe-a0ff-fb9c914e6485\")) {                    Plotly.newPlot(                        \"dbe46988-4512-46fe-a0ff-fb9c914e6485\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"word=%{x}<br>frequency=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"like\",\"know\",\"just\",\"april\",\"time\",\"clutch\",\"ve\",\"muslims\",\"people\",\"degrees\",\"ee\",\"good\",\"years\",\"armenian\",\"year\",\"got\",\"say\",\"better\",\"way\",\"armenians\"],\"xaxis\":\"x\",\"y\":[30,28,24,24,22,20,17,17,17,17,16,15,15,15,13,13,13,13,13,13],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"word\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"frequency\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Top 20 Words in the Corpus\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('dbe46988-4512-46fe-a0ff-fb9c914e6485');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert input_texts to a single list of strings\n",
    "corpus = [' '.join(text.split()) for text in input_texts]\n",
    "\n",
    "# Create a CountVectorizer object to count the frequency of each word in the corpus\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Get the top N words by frequency\n",
    "N = 20\n",
    "counts = X.sum(axis=0)\n",
    "word_freq = [(word, counts[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "word_freq_sorted = sorted(word_freq, key=lambda x: x[1], reverse=True)[:N]\n",
    "words = [x[0] for x in word_freq_sorted]\n",
    "freqs = [x[1] for x in word_freq_sorted]\n",
    "\n",
    "# Create a DataFrame to store the top N words and their frequencies\n",
    "df = pd.DataFrame({'word': words, 'frequency': freqs})\n",
    "\n",
    "# Create a bar chart\n",
    "fig = px.bar(df, x='word', y='frequency', title=f'Top {N} Words in the Corpus')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08eg6eEAC1OI"
   },
   "source": [
    "Visualizaiton Code block 2: Scatter plot to visualize the relationship between summary length and ROUGE scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJQz0EhZmhNv"
   },
   "source": [
    "**The following code** creates a scatter plot that shows the relationship between the input length and the ROUGE-1 scores of the generated summaries. It starts by creating a pandas DataFrame that stores the ROUGE-1, ROUGE-2, and ROUGE-L scores, as well as the input length for each input in the test set. The scores are extracted from the rouge_scores list created in the previous code block. The tokenizer.decode method is used to decode the input_ids to a string and calculate its length.\n",
    "\n",
    "Next, the DataFrame is plotted as a scatter plot using the px.scatter function from the plotly.express library. The x argument is set to 'input_length' and the y argument is set to 'rouge1' to plot the ROUGE-1 scores against the input length. The title argument is used to set the title of the plot. The resulting plot shows how the ROUGE-1 scores are distributed across the input lengths of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "PJGIuukgGtki",
    "outputId": "19520538-3676-45c4-b45b-49583fad91ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"adb3984c-b8d1-4e71-a9a5-3b592b7eabfa\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"adb3984c-b8d1-4e71-a9a5-3b592b7eabfa\")) {                    Plotly.newPlot(                        \"adb3984c-b8d1-4e71-a9a5-3b592b7eabfa\",                        [{\"hovertemplate\":\"input_length=%{x}<br>rouge1=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[675,848,501,110,450,552,716,96,2129,523,2091,601,222,172,1910,156,679,471,259,200,15,2061,307,532,567,685,362,104,459,291,455,945,321,784,593,336,535,202],\"xaxis\":\"x\",\"y\":[0.12068965517241378,0.15873015873015875,0.10526315789473684,0.08403361344537814,0.08333333333333334,0.1218274111675127,0.0,0.08421052631578947,0.0,0.17857142857142858,0.043478260869565216,0.08333333333333333,0.15,0.20000000000000004,0.06896551724137931,0.09756097560975609,0.0,0.07547169811320754,0.08108108108108109,0.0,0.0,0.0,0.0,0.0,0.09999999999999999,0.0,0.17105263157894737,0.05309734513274336,0.10300429184549355,0.0,0.045454545454545456,0.07317073170731708,0.126984126984127,0.19047619047619044,0.0,0.22222222222222224,0.057971014492753624,0.11594202898550723],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"input_length\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"rouge1\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROUGE-1 Scores vs. Input Length\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('adb3984c-b8d1-4e71-a9a5-3b592b7eabfa');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame to store the ROUGE scores and summary lengths\n",
    "df = pd.DataFrame({'rouge1': [score['rouge1'].fmeasure for score in rouge_scores],\n",
    "                   'rouge2': [score['rouge2'].fmeasure for score in rouge_scores],\n",
    "                   'rougeL': [score['rougeL'].fmeasure for score in rouge_scores],\n",
    "                   'input_length': [len(tokenizer.decode(input_ids['input_ids'][0], skip_special_tokens=True)) for input_ids in test_inputs]})\n",
    "\n",
    "# Create a scatter plot\n",
    "fig = px.scatter(df, x='input_length', y='rouge1', title='ROUGE-1 Scores vs. Input Length')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0L21LaQtDLbC"
   },
   "source": [
    "Visualization Code block 3: Heatmap of Correlation Matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-foRiplKmr8X"
   },
   "source": [
    "**This final code block** is creating a heatmap to visualize the correlation matrix between ROUGE scores. It starts by creating a Pandas DataFrame df that stores the ROUGE scores for each generated summary. The columns of the DataFrame correspond to the different ROUGE metrics (ROUGE-1, ROUGE-2, ROUGE-L), and the rows correspond to each generated summary. The ROUGE scores are extracted from the rouge_scores list of dictionaries, which was generated in a previous step.\n",
    "\n",
    "The corr variable stores the correlation matrix calculated using the corr() function of Pandas. This function returns a correlation matrix that shows the pairwise correlation between each pair of columns in the DataFrame.\n",
    "\n",
    "Finally, a heatmap is created using Plotly Express px.imshow() function, which takes the correlation matrix as input and maps the values to a color scale. The color scale is chosen to be red and blue (color_continuous_scale='RdBu'), where red represents a positive correlation, and blue represents a negative correlation. The heatmap shows the correlation matrix of the ROUGE scores for each metric, which provides insights into the relationship between the different ROUGE scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "fwn5tDlHGx2z",
    "outputId": "d347f9f3-7ee7-4f6a-8371-fc30c27d99c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"ce8c25d9-db76-4318-bf8f-20dacdc9d827\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ce8c25d9-db76-4318-bf8f-20dacdc9d827\")) {                    Plotly.newPlot(                        \"ce8c25d9-db76-4318-bf8f-20dacdc9d827\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"ROUGE-1\",\"ROUGE-2\",\"ROUGE-L\"],\"y\":[\"ROUGE-1\",\"ROUGE-2\",\"ROUGE-L\"],\"z\":[[1.0,0.4092598308426732,0.9269165533309919],[0.4092598308426732,1.0,0.4830950490454061],[0.9269165533309919,0.4830950490454061,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]]},\"title\":{\"text\":\"Correlation Matrix of ROUGE Scores\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ce8c25d9-db76-4318-bf8f-20dacdc9d827');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame to store the ROUGE scores\n",
    "df = pd.DataFrame({'rouge1': [score['rouge1'].fmeasure for score in rouge_scores],\n",
    "                   'rouge2': [score['rouge2'].fmeasure for score in rouge_scores],\n",
    "                   'rougeL': [score['rougeL'].fmeasure for score in rouge_scores]})\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Create a heatmap\n",
    "fig = px.imshow(corr, x=['ROUGE-1', 'ROUGE-2', 'ROUGE-L'], y=['ROUGE-1', 'ROUGE-2', 'ROUGE-L'], \n",
    "                color_continuous_scale='RdBu', title='Correlation Matrix of ROUGE Scores')\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
